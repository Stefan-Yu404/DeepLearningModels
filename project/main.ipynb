{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49eecf9c",
   "metadata": {},
   "source": [
    "## Main file for project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2792c887",
   "metadata": {},
   "source": [
    "### Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce714263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e830161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Munch data preprocessing, only need to run once\n",
    "########################################\n",
    "# make sure the data are downloaded from \n",
    "# https://www.kaggle.com/code/isaienkov/how-to-start-with-munch-s-paintings\n",
    "# and set fileDir to the folder\n",
    "########################################\n",
    "# Monet painting data are from \n",
    "# https://www.kaggle.com/code/dimitreoliveira/introduction-to-cyclegan-monet-paintings/notebook\n",
    "# already cleaned and reshaped\n",
    "\n",
    "# This is the directory of the unzipped file you download\n",
    "fileDir = \"../../../Desktop/NU/Deep_Learning/archive/\"\n",
    "imgIndex = pd.read_csv(fileDir + \"/edvard_munch.csv\")\n",
    "fileList = imgIndex[\"filename\"]\n",
    "\n",
    "# load each individual image, resize and save\n",
    "processDir = fileDir + \"/munch_processed\"\n",
    "if not os.path.exists(processDir):\n",
    "    os.makedirs(processDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "534f87ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Pytorch dataset\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset): \n",
    "    def __init__(self, MunchDir, MonetDir, MunchName, MonetName, transform=None, target_transform=None): \n",
    "        imgs = []                      \n",
    "        for name in MunchName:\n",
    "            imgs.append((name,1))\n",
    "        for name in MonetName:\n",
    "            imgs.append((name,0))\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    " \n",
    "    def __getitem__(self, index):  \n",
    "        fn, label = self.imgs[index]\n",
    "        if label == 1:\n",
    "            img = Image.open(MunchDir + '/' + fn).convert('RGB')\n",
    "        if label == 0:\n",
    "            img = Image.open(MonetDir + '/' + fn).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img) \n",
    "        return img, label\n",
    " \n",
    "    def __len__(self): \n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "551c0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing preperation\n",
    "\n",
    "# Munch processed image\n",
    "MunchDir = '../../../Desktop/NU/Deep_Learning/archive/munch_processed'\n",
    "MunchFileName = np.array(os.listdir(MunchDir))\n",
    "\n",
    "# Monet processed image\n",
    "MonetDir = '../../../Desktop/NU/Deep_Learning/archive/munch_processed'\n",
    "MonetFileName = np.array(os.listdir(MonetDir))\n",
    "\n",
    "# training set size\n",
    "np.random.seed(100)\n",
    "trainRatio = 0.7\n",
    "\n",
    "trainMunchIdx = np.random.choice(len(MunchFileName), int(trainRatio * len(MunchFileName)), replace=False)\n",
    "trainMonetIdx = np.random.choice(len(MonetFileName), int(trainRatio * len(MonetFileName)), replace=False)\n",
    "\n",
    "trainMunch = MunchFileName[trainMunchIdx]\n",
    "trainMonet = MonetFileName[trainMonetIdx]\n",
    "\n",
    "testMunch = np.delete(MunchFileName, trainMunchIdx)\n",
    "testMonet = np.delete(MonetFileName, trainMonetIdx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b72fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Model\n",
    "# Refer to the model Provided by Kaiming, H., Xiangyu, Z. et al. Deep Residual Learning for Image Recognition(2015),https://arxiv.org/abs/1512.03385 \n",
    "\n",
    "# Define basic ResNet Blocks: ConvBlock and IdentityBlock\n",
    "class ConvBlock(nn.Module):\n",
    "    '''\n",
    "    The basic element of ResNet: Convolutional Block, including 3 convolution layers\n",
    "    '''\n",
    "    def __init__(self, in_channel:int, filters:list, strides = 1):\n",
    "        '''\n",
    "        :param in_channel: input dim\n",
    "        :param filters: The number of filters for each concolutional layer (lenghth = 3).\n",
    "        :param strides: the stride for the first layer, default 1.\n",
    "        '''\n",
    "        super(ConvBlock,self).__init__()\n",
    "        F1, F2, F3 = filters\n",
    "        self.stage = nn.Sequential(\n",
    "            nn.Conv2d(in_channel,F1,1,stride=strides, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(F1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(F1,F2,3,stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(F2,F3,1,stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(F3),\n",
    "        )\n",
    "        self.shortcut_1 = nn.Conv2d(in_channel, F3, 1,stride = strides, padding=0, bias=False)\n",
    "        self.batch_1 = nn.BatchNorm2d(F3)\n",
    "        self.relu_1 = nn.ReLU(True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X_shortcut = self.shortcut_1(X)\n",
    "        X_shortcut = self.batch_1(X_shortcut)\n",
    "        X = self.stage(X)\n",
    "        X = X + X_shortcut\n",
    "        X = self.relu_1(X)\n",
    "        return X    \n",
    "    \n",
    "class IndentityBlock(nn.Module):\n",
    "    '''\n",
    "    Simliar to ConvBlock, but works with ConvBlock as Bottle Neck.\n",
    "    '''\n",
    "    def __init__(self, in_channel:int, filters: list):\n",
    "        '''\n",
    "        :param in_channel: input dim\n",
    "        :param filters: The number of filters for each concolutional layer (lenghth = 3).\n",
    "        '''\n",
    "        super(IndentityBlock,self).__init__()\n",
    "        F1, F2, F3 = filters\n",
    "        self.stage = nn.Sequential(\n",
    "            nn.Conv2d(in_channel,F1,1,stride=1, bias=False),\n",
    "            nn.BatchNorm2d(F1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(F1,F2,3,stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(F2,F3,1,stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(F3),\n",
    "        )\n",
    "        self.relu_1 = nn.ReLU(True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X_shortcut = X\n",
    "        X = self.stage(X)\n",
    "        X = X + X_shortcut\n",
    "        X = self.relu_1(X)\n",
    "        return X\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    '''\n",
    "    ResNet\n",
    "    '''\n",
    "    def __init__(self, n_class: int):\n",
    "        '''\n",
    "        :param n_class: output dimension.\n",
    "        '''\n",
    "        super(ResNet,self).__init__()\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(3,64,7,stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3,2,padding=1),\n",
    "        )\n",
    "        self.stage2 = nn.Sequential(\n",
    "            ConvBlock(64, filters=[64, 64, 256], strides=1),\n",
    "            IndentityBlock(256, [64, 64, 256]),\n",
    "            IndentityBlock(256, [64, 64, 256]),\n",
    "        )\n",
    "        self.stage3 = nn.Sequential(\n",
    "            ConvBlock(256, filters=[128, 128, 512], strides=2),\n",
    "            IndentityBlock(512, [128, 128, 512]),\n",
    "            IndentityBlock(512, [128, 128, 512]),\n",
    "            IndentityBlock(512, [128, 128, 512]),\n",
    "        )\n",
    "        self.stage4 = nn.Sequential(\n",
    "            ConvBlock(512, filters=[256, 256, 1024], strides=2),\n",
    "            IndentityBlock(1024, [256, 256, 1024]),\n",
    "            IndentityBlock(1024, [256, 256, 1024]),\n",
    "            IndentityBlock(1024, [256, 256, 1024]),\n",
    "            IndentityBlock(1024, [256, 256, 1024]),\n",
    "            IndentityBlock(1024, [256, 256, 1024]),\n",
    "        )\n",
    "        self.stage5 = nn.Sequential(\n",
    "            ConvBlock(1024, filters=[512, 512, 2048], strides=2),\n",
    "            IndentityBlock(2048, [512, 512, 2048]),\n",
    "            IndentityBlock(2048, [512, 512, 2048]),\n",
    "        )\n",
    "        self.pool = nn.AvgPool2d(2,2,padding=1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2048*5*5,n_class)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = self.stage1(X)\n",
    "        out = self.stage2(out)\n",
    "        out = self.stage3(out)\n",
    "        out = self.stage4(out)\n",
    "        out = self.stage5(out)\n",
    "        out = self.pool(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "617897cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2048, 5, 5])\n",
      "torch.Size([64, 2048, 5, 5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     24\u001b[0m ly \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 26\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m BCE_loss(out, y)\n\u001b[1;32m     28\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLStart/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[28], line 116\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    114\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage1(X)\n\u001b[1;32m    115\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage2(out)\n\u001b[0;32m--> 116\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage4(out)\n\u001b[1;32m    118\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage5(out)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLStart/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLStart/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLStart/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[28], line 66\u001b[0m, in \u001b[0;36mIndentityBlock.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     64\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage(X)\n\u001b[1;32m     65\u001b[0m X \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m+\u001b[39m X_shortcut\n\u001b[0;32m---> 66\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu_1\u001b[49m(X)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/MLStart/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_is_full_backward_hook\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1192\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_full_backward_hook \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, \u001b[39m'\u001b[39m\u001b[39mModule\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m   1195\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1196\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_size = 256\n",
    "batchsz = 64\n",
    "lr = 0.0002\n",
    "epoches = 80\n",
    "\n",
    "model = ResNet(2)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "BCE_loss = torch.nn.CrossEntropyLoss()\n",
    "# Load data\n",
    "\n",
    "train_data = MyDataset(MunchDir, MonetDir, trainMunch, trainMonet, transform=transforms.ToTensor())\n",
    "test_data = MyDataset(MunchDir, MonetDir, testMunch, testMonet, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batchsz, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batchsz, shuffle = False)\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for batch_idx, batch_data in enumerate(train_loader,1):\n",
    "        x, y = batch_data\n",
    "        x = x.float().to(device)\n",
    "        ly = y.long().to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = BCE_loss(out, y)\n",
    "        running_loss += loss.item() * y.size(0)\n",
    "        _,pred = torch.max(out,1)  \n",
    "        num_correct = (pred == y).sum()\n",
    "        running_acc += num_correct.item()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward() \n",
    "        optim.step() \n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Train{} epoch, Loss: {:.6f},Acc: {:.6f}'.format(epoch+1,running_loss / (len(train_data)),\n",
    "                                                               running_acc / (len(train_data))))\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        eval_acc = 0\n",
    "        for data in test_loader:\n",
    "            x,y = data\n",
    "            x = x.float().to(device)\n",
    "            y = y.long().to(device)\n",
    "            out = model(x)\n",
    "            loss = BCE_loss(out, y)\n",
    "            eval_loss += loss.item() * y.size(0)\n",
    "            _,pred = torch.max(out,1)   \n",
    "            num_correct = (pred == y).sum() \n",
    "            eval_acc += num_correct.item() \n",
    "\n",
    "        print('Test Loss:{:.6f},Acc: {:.6f}'\n",
    "            .format(eval_loss/ (len(test_data)),eval_acc * 1.0/(len(test_data))))\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546d03c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('MLStart')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "775c9ee0aaa161e287fb0ef0ae95a93e422a6787216f3c1de737ce48f83b4151"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
