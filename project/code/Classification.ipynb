{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920ca319",
   "metadata": {},
   "source": [
    "# Main file for classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1610cd1",
   "metadata": {},
   "source": [
    "Code is adapted from class CNN notebook, and the following tutorial https://www.kaggle.com/code/songseungwon/cyclegan-tutorial-from-scratch-monet-to-photo/notebook ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e74b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f44fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Munch data preprocessing, only need to run once\n",
    "########################################\n",
    "# make sure the data are downloaded from \n",
    "# https://www.kaggle.com/code/isaienkov/how-to-start-with-munch-s-paintings\n",
    "# and set fileDir to the folder\n",
    "########################################\n",
    "# Monet painting data are from \n",
    "# https://www.kaggle.com/code/dimitreoliveira/introduction-to-cyclegan-monet-paintings/notebook\n",
    "# already cleaned and reshaped\n",
    "\n",
    "# # This is the directory of the unzipped file you download\n",
    "# fileDir = \"../../../Desktop/NU/Deep_Learning/archive/\"\n",
    "# imgIndex = pd.read_csv(fileDir + \"/edvard_munch.csv\")\n",
    "# fileList = imgIndex[\"filename\"]\n",
    "\n",
    "# # load each individual image, resize and save\n",
    "# processDir = fileDir + \"/munch_processed\"\n",
    "# if not os.path.exists(processDir):\n",
    "#     os.makedirs(processDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4ad6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Pytorch dataset\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset): \n",
    "    def __init__(self, MunchDir, MonetDir, MunchName, MonetName, transform=None, target_transform=None): \n",
    "        imgs = []                      \n",
    "        for name in MunchName:\n",
    "            imgs.append((name,1))\n",
    "        for name in MonetName:\n",
    "            imgs.append((name,0))\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    " \n",
    "    def __getitem__(self, index):  \n",
    "        fn, label = self.imgs[index]\n",
    "        if label == 1:\n",
    "            img = Image.open(MunchDir + '/' + fn).convert('RGB')\n",
    "        if label == 0:\n",
    "            img = Image.open(MonetDir + '/' + fn).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img) \n",
    "        return img, label\n",
    " \n",
    "    def __len__(self): \n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing preperation\n",
    "\n",
    "# Munch processed image\n",
    "MunchDir = \"/kaggle/input/all-image/archive/munch_processed\"\n",
    "MunchFileName = np.array(os.listdir(MunchDir))\n",
    "\n",
    "# Monet processed image\n",
    "MonetDir = \"/kaggle/input/all-image/archive/monet_processed\"\n",
    "MonetFileName = np.array(os.listdir(MonetDir))\n",
    "\n",
    "# training set size\n",
    "np.random.seed(100)\n",
    "trainRatio = 0.7\n",
    "\n",
    "trainMunchIdx = np.random.choice(len(MunchFileName), int(trainRatio * len(MunchFileName)), replace=False)\n",
    "trainMonetIdx = np.random.choice(len(MonetFileName), int(trainRatio * len(MonetFileName)), replace=False)\n",
    "\n",
    "trainMunch = MunchFileName[trainMunchIdx]\n",
    "trainMonet = MonetFileName[trainMonetIdx]\n",
    "\n",
    "testMunch = np.delete(MunchFileName, trainMunchIdx)\n",
    "testMonet = np.delete(MonetFileName, trainMonetIdx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38b3564",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b484f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Model\n",
    "# Refer to the model Provided by Kaiming, H., Xiangyu, Z. et al. Deep Residual Learning for Image Recognition(2015),https://arxiv.org/abs/1512.03385 \n",
    "\n",
    "# Define basic ResNet Blocks: ConvBlock and IdentityBlock\n",
    "class ConvBlock(nn.Module):\n",
    "    '''\n",
    "    The basic element of ResNet: Convolutional Block, including 3 convolution layers\n",
    "    '''\n",
    "    def __init__(self, in_channel:int, filters:list, strides = 1):\n",
    "        '''\n",
    "        :param in_channel: input dim\n",
    "        :param filters: The number of filters for each concolutional layer (lenghth = 3).\n",
    "        :param strides: the stride for the first layer, default 1.\n",
    "        '''\n",
    "        super(ConvBlock,self).__init__()\n",
    "        F1, F2, F3 = filters\n",
    "        self.stage = nn.Sequential(\n",
    "            nn.Conv2d(in_channel,F1,1,stride=strides, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(F1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(F1,F2,3,stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(F2,F3,1,stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(F3),\n",
    "        )\n",
    "        self.shortcut_1 = nn.Conv2d(in_channel, F3, 1,stride = strides, padding=0, bias=False)\n",
    "        self.batch_1 = nn.BatchNorm2d(F3)\n",
    "        self.relu_1 = nn.ReLU(True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X_shortcut = self.shortcut_1(X)\n",
    "        X_shortcut = self.batch_1(X_shortcut)\n",
    "        X = self.stage(X)\n",
    "        X = X + X_shortcut\n",
    "        X = self.relu_1(X)\n",
    "        return X    \n",
    "    \n",
    "class IndentityBlock(nn.Module):\n",
    "    '''\n",
    "    Simliar to ConvBlock, but works with ConvBlock as Bottle Neck.\n",
    "    '''\n",
    "    def __init__(self, in_channel:int, filters: list):\n",
    "        '''\n",
    "        :param in_channel: input dim\n",
    "        :param filters: The number of filters for each concolutional layer (lenghth = 3).\n",
    "        '''\n",
    "        super(IndentityBlock,self).__init__()\n",
    "        F1, F2, F3 = filters\n",
    "        self.stage = nn.Sequential(\n",
    "            nn.Conv2d(in_channel,F1,1,stride=1, bias=False),\n",
    "            nn.BatchNorm2d(F1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(F1,F2,3,stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(F2,F3,1,stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(F3),\n",
    "        )\n",
    "        self.relu_1 = nn.ReLU(True)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X_shortcut = X\n",
    "        X = self.stage(X)\n",
    "        X = X + X_shortcut\n",
    "        X = self.relu_1(X)\n",
    "        return X\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    '''\n",
    "    ResNet\n",
    "    '''\n",
    "    def __init__(self, n_class: int):\n",
    "        '''\n",
    "        :param n_class: output dimension.\n",
    "        '''\n",
    "        super(ResNet,self).__init__()\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(3,64,7,stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(3,2,padding=1),\n",
    "        )\n",
    "        self.stage2 = nn.Sequential(\n",
    "            ConvBlock(64, filters=[64, 64, 256], strides=1),\n",
    "            IndentityBlock(256, [64, 64, 256]),\n",
    "            IndentityBlock(256, [64, 64, 256]),\n",
    "        )\n",
    "        self.stage3 = nn.Sequential(\n",
    "            ConvBlock(256, filters=[128, 128, 512], strides=2),\n",
    "            IndentityBlock(512, [128, 128, 512]),\n",
    "            IndentityBlock(512, [128, 128, 512]),\n",
    "            IndentityBlock(512, [128, 128, 512]),\n",
    "        )\n",
    "        self.stage4 = nn.Sequential(\n",
    "            ConvBlock(512, filters=[256, 256, 1024], strides=2),\n",
    "            IndentityBlock(1024, [256, 256, 1024]),\n",
    "            IndentityBlock(1024, [256, 256, 1024]),\n",
    "            IndentityBlock(1024, [256, 256, 1024]),\n",
    "            IndentityBlock(1024, [256, 256, 1024]),\n",
    "            IndentityBlock(1024, [256, 256, 1024]),\n",
    "        )\n",
    "        self.stage5 = nn.Sequential(\n",
    "            ConvBlock(1024, filters=[512, 512, 2048], strides=2),\n",
    "            IndentityBlock(2048, [512, 512, 2048]),\n",
    "            IndentityBlock(2048, [512, 512, 2048]),\n",
    "        )\n",
    "        self.pool = nn.AvgPool2d(2,2,padding=1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2048*5*5,n_class)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = self.stage1(X)\n",
    "        out = self.stage2(out)\n",
    "        out = self.stage3(out)\n",
    "        out = self.stage4(out)\n",
    "        out = self.stage5(out)\n",
    "        out = self.pool(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c051d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_size = 256\n",
    "batchsz = 64\n",
    "lr = 0.0002\n",
    "epoches = 10\n",
    "\n",
    "model = ResNet(2)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "BCE_loss = torch.nn.CrossEntropyLoss()\n",
    "# Load data\n",
    "\n",
    "train_data = MyDataset(MunchDir, MonetDir, trainMunch, trainMonet, transform=transforms.ToTensor())\n",
    "test_data = MyDataset(MunchDir, MonetDir, testMunch, testMonet, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batchsz, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batchsz, shuffle = False)\n",
    "\n",
    "results = defaultdict(list)\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for batch_idx, batch_data in enumerate(train_loader,1):\n",
    "        x, y = batch_data\n",
    "        x = x.float().to(device)\n",
    "        y = y.long().to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = BCE_loss(out, y)\n",
    "        running_loss += loss.item() * y.size(0)\n",
    "        _,pred = torch.max(out,1)  \n",
    "        num_correct = (pred == y).sum()\n",
    "        running_acc += num_correct.item()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward() \n",
    "        optim.step() \n",
    "\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print('Train{} epoch, Loss: {:.6f},Acc: {:.6f}'.format(epoch+1,running_loss / (len(train_data)),\n",
    "                                                               running_acc / (len(train_data))))\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        eval_acc = 0\n",
    "        for data in test_loader:\n",
    "            x,y = data\n",
    "            x = x.float().to(device)\n",
    "            y = y.long().to(device)\n",
    "            out = model(x)\n",
    "            loss = BCE_loss(out, y)\n",
    "            eval_loss += loss.item() * y.size(0)\n",
    "            _,pred = torch.max(out,1)   \n",
    "            num_correct = (pred == y).sum() \n",
    "            eval_acc += num_correct.item() \n",
    "\n",
    "        print('Test Loss:{:.6f},Acc: {:.6f}'\n",
    "            .format(eval_loss/ (len(test_data)),eval_acc * 1.0/(len(test_data))))\n",
    "        \n",
    "        results[\"train_acc\"].append(running_acc / (len(train_data)))\n",
    "        results[\"test_acc\"].append(eval_acc * 1.0/(len(test_data)))\n",
    "        results[\"train_loss\"].append(running_loss / (len(train_data)))\n",
    "        results[\"test_loss\"].append(eval_loss/ (len(test_data)))\n",
    "        torch.cuda.empty_cache()\n",
    "                                     \n",
    "plot(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47f91ae",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6981b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, linear_layer_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.linear_layer_size = linear_layer_size\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=2)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 16, kernel_size=2)\n",
    "        self.linear = torch.nn.Linear(linear_layer_size, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        relu = torch.nn.ReLU()\n",
    "        maxpool = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = maxpool(relu(x))\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = maxpool(relu(x))\n",
    "\n",
    "        x = x.reshape(batch_size, self.linear_layer_size)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one_epoch(model, optimizer, X, y, train=True):\n",
    "\n",
    "    if train:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    output = model(X).squeeze()\n",
    "    acc = torch.sum(torch.argmax(output, dim=1) == y) / y.size(0)\n",
    "    loss = torch.nn.CrossEntropyLoss()(output, y)\n",
    "\n",
    "    if train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Detach tells torch to stop tracking a tensor's gradients\n",
    "    return acc.detach(), loss.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104fa2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(model):\n",
    "    \"\"\" \n",
    "    A simple functon that prints out a PyTorch model's structural details\n",
    "    \"\"\"\n",
    "    # Print the number of parameters in the model\n",
    "    parameter_count =  sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(\"In total, this network has \", parameter_count, \" parameters\")\n",
    "\n",
    "def demo(model, data, n_epochs=100, verbose=False):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    results = defaultdict(list)\n",
    "    for i in range(n_epochs):\n",
    "        train_acc, train_loss = run_one_epoch(model, optimizer, X_train, y_train, train=True)\n",
    "        test_acc, test_loss = run_one_epoch(model, optimizer, X_test, y_test, train=False)\n",
    "\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "\n",
    "        if verbose and (i + 1) % (n_epochs // 10) == 0:\n",
    "            train_stats = f\"Train loss: {train_loss:.3f} Train accuracy: {100 * train_acc:4.1f}%\"\n",
    "            test_stats = f\"Test loss: {test_loss:.3f} Test accuracy: {100 * test_acc:.1f}%\"\n",
    "            print(f\"{i + 1:4d} {train_stats} {test_stats}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def plot(results):    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5),\n",
    "                             constrained_layout=True)\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.set_title(\"Loss per Epoch\")\n",
    "    train_loss = results[\"train_loss\"]\n",
    "    test_loss = results[\"test_loss\"]\n",
    "    n_epochs = len(train_loss)\n",
    "    ax.plot(np.arange(n_epochs), train_loss, c='r', label='Train Loss')\n",
    "    ax.plot(np.arange(n_epochs), test_loss, c='b', label='Test Loss')\n",
    "    ax.legend(loc=\"best\")\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.set_ylim(ymin, 2 * ymax)\n",
    "\n",
    "    # Bottom right\n",
    "    ax = axes[1]\n",
    "    ax.set_title(\"Accuracy per Epoch\")\n",
    "    train_acc = results[\"train_acc\"]\n",
    "    test_acc = results[\"test_acc\"]\n",
    "    n_epochs = len(train_acc)\n",
    "    ax.plot(np.arange(n_epochs), train_acc, c='r', label='Train Acc')\n",
    "    ax.plot(np.arange(n_epochs), test_acc, c='b', label='Test Acc')\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_ylim(0, 1.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3202ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "image_size = 256\n",
    "batchsz = 64\n",
    "lr = 0.0002\n",
    "epoches = 10\n",
    "\n",
    "model = CNN(linear_layer_size=63504)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "BCE_loss = torch.nn.CrossEntropyLoss()\n",
    "# Load data\n",
    "\n",
    "train_data = MyDataset(MunchDir, MonetDir, trainMunch, trainMonet, transform=transforms.ToTensor())\n",
    "test_data = MyDataset(MunchDir, MonetDir, testMunch, testMonet, transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batchsz, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batchsz, shuffle = False)\n",
    "\n",
    "results = defaultdict(list)\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for batch_idx, batch_data in enumerate(train_loader,1):\n",
    "        x, y = batch_data\n",
    "        x = x.float().to(device)\n",
    "        y = y.long().to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = BCE_loss(out, y)\n",
    "        running_loss += loss.item() * y.size(0)\n",
    "        _,pred = torch.max(out,1)  \n",
    "        num_correct = (pred == y).sum()\n",
    "        running_acc += num_correct.item()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward() \n",
    "        optim.step() \n",
    "\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print('Train{} epoch, Loss: {:.6f},Acc: {:.6f}'.format(epoch+1,running_loss / (len(train_data)),\n",
    "                                                               running_acc / (len(train_data))))\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        eval_acc = 0\n",
    "        for data in test_loader:\n",
    "            x,y = data\n",
    "            x = x.float().to(device)\n",
    "            y = y.long().to(device)\n",
    "            out = model(x)\n",
    "            loss = BCE_loss(out, y)\n",
    "            eval_loss += loss.item() * y.size(0)\n",
    "            _,pred = torch.max(out,1)   \n",
    "            num_correct = (pred == y).sum() \n",
    "            eval_acc += num_correct.item() \n",
    "\n",
    "        print('Test Loss:{:.6f},Acc: {:.6f}'\n",
    "            .format(eval_loss/ (len(test_data)),eval_acc * 1.0/(len(test_data))))\n",
    "        \n",
    "        results[\"train_acc\"].append(running_acc / (len(train_data)))\n",
    "        results[\"test_acc\"].append(eval_acc * 1.0/(len(test_data)))\n",
    "        results[\"train_loss\"].append(running_loss / (len(train_data)))\n",
    "        results[\"test_loss\"].append(eval_loss/ (len(test_data)))\n",
    "        torch.cuda.empty_cache()\n",
    "                                     \n",
    "plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40693e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b79ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
